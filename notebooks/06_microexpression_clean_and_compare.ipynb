{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# Notebook 06  Micro-Expression Cleaning & Dataset Comparison\n",
    "Last polished on: 2025-10-15\n",
    "\n",
    "**Notebook Purpose**  \n",
    "This notebook prepares the micro-expression datasets (SMIC and CASME II) for symbolic audit and multimodal fusion. Tasks include:\n",
    "\n",
    "- Loading and inspecting SMIC and CASME II raw metadata\n",
    "- Cleaning emotion labels, removing bad samples, and flagging ambiguity\n",
    "- Aligning emotion categories with DAIC-WOZ taxonomy\n",
    "- Preparing `.parquet` outputs for use in fusion and Z3 logic audits\n",
    "\n",
    "This step is foundational for building symbolic rules on frame-level emotion masking, dissociation, and ambiguous affect patterns (Notebook 07).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 06.0  Initialization & Path Setup\n",
    "# -----------------------------------------------------------------------------\n",
    "# - Sets up all paths for data and output locations\n",
    "# - Confirms directories exist or creates them\n",
    "# - Confirms notebook is loaded correctly\n",
    "# =============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Define root paths (adjusted for notebook use) ----------------------------\n",
    "ROOT = Path().resolve().parent  # One level up from /notebooks/\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "CHECKS_DIR = ROOT / \"outputs\" / \"checks\"\n",
    "VIS_DIR = ROOT / \"outputs\" / \"visuals\"\n",
    "\n",
    "# --- Create folders if missing ------------------------------------------------\n",
    "CHECKS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Startup confirmation -----------------------------------------------------\n",
    "print(\"âœ… Notebook 06 initialized successfully\")\n",
    "print(f\"ðŸ“‚ Root directory:       {ROOT}\")\n",
    "print(f\"ðŸ“‚ Raw data directory:   {RAW_DIR}\")\n",
    "print(f\"ðŸ“‚ Processed directory:  {PROCESSED_DIR}\")\n",
    "print(f\"ðŸ“‚ Outputs > Checks:     {CHECKS_DIR}\")\n",
    "print(f\"ðŸ“‚ Outputs > Visuals:    {VIS_DIR}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.1 | CASME II Cleaning & Structuring\n",
    "\n",
    "**Source:** `CASME2-coding-20140508.xlsx`  \n",
    "**Output:** `casme2_cleaned.parquet`  \n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Load CASME II label + timing metadata  \n",
    "- Clean and standardize columns (onset, offset, AUs, etc.)  \n",
    "- Normalize emotion labels (lowercase)  \n",
    "- Output tidy .parquet for fusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… RAW_DIR:\", RAW_DIR)\n",
    "print(\"ðŸ›£ï¸ Full path:\", RAW_DIR / \"CASME2\" / \"CASME2-coding-20140508.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.1  Load CASME II Metadata File\n",
    "# =============================================================================\n",
    "# Goal:\n",
    "#   - Read Excel spreadsheet containing CASME II label + timing metadata\n",
    "#   - Confirm file loads successfully and preview structure\n",
    "#   - Check for column names, shape, and class label distribution\n",
    "# =============================================================================\n",
    "\n",
    "# --- Define CASME II spreadsheet path ----------------------------------------\n",
    "casme_meta_path = RAW_DIR / \"CASME2\" / \"CASME2-coding-20140508.xlsx\"\n",
    "\n",
    "# --- Load the spreadsheet safely ---------------------------------------------\n",
    "try:\n",
    "    casme_df = pd.read_excel(casme_meta_path)\n",
    "    print(f\"âœ… Loaded CASME II metadata: {casme_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ File not found: {casme_meta_path}\")\n",
    "    casme_df = None\n",
    "\n",
    "# --- Preview structure if loaded correctly -----------------------------------\n",
    "if casme_df is not None:\n",
    "    # Display first few rows\n",
    "    display(casme_df.head(3))\n",
    "    \n",
    "    # Show column types and null counts\n",
    "    display(casme_df.info())\n",
    "\n",
    "    # View emotion label distribution (if column exists)\n",
    "    if 'Estimated Emotion' in casme_df.columns:\n",
    "        print(\"Unique emotion labels:\")\n",
    "        print(casme_df['Estimated Emotion'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.1.2 Clean & Standardize CASME II Metadata\n",
    "# -----------------------------------------------------------------------------\n",
    "# - Drops empty or irrelevant columns (e.g., Unnamed)\n",
    "# - Normalizes emotion labels for consistency\n",
    "# - Renames key columns for model fusion (onset, offset, duration)\n",
    "# - Handles any formatting issues with ApexFrame, Action Units, etc.\n",
    "# =============================================================================\n",
    "\n",
    "# --- Drop junk or empty columns ----------------------------------------------\n",
    "drop_cols = [col for col in casme_df.columns if \"Unnamed\" in col]\n",
    "casme_df.drop(columns=drop_cols, inplace=True)\n",
    "print(f\"ðŸ§¹ Dropped columns: {drop_cols}\")\n",
    "\n",
    "# --- Rename for fusion alignment ---------------------------------------------\n",
    "casme_df.rename(columns={\n",
    "    \"OnsetFrame\": \"Onset\",\n",
    "    \"OffsetFrame\": \"Offset\",\n",
    "    \"ApexFrame\": \"Peak\",\n",
    "    \"Subject\": \"SubjectID\",\n",
    "    \"Estimated Emotion\": \"Emotion\",\n",
    "    \"Action Units\": \"ActionUnits\"\n",
    "}, inplace=True)\n",
    "\n",
    "# --- Normalize emotion labels ------------------------------------------------\n",
    "casme_df[\"Emotion\"] = casme_df[\"Emotion\"].str.strip().str.lower()\n",
    "\n",
    "# --- Normalize ActionUnits if not already string -----------------------------\n",
    "casme_df[\"ActionUnits\"] = casme_df[\"ActionUnits\"].astype(str)\n",
    "\n",
    "# --- Handle ApexFrame (Peak) column safely -----------------------------------\n",
    "casme_df[\"Peak\"] = pd.to_numeric(casme_df[\"Peak\"], errors=\"coerce\")\n",
    "\n",
    "# --- Add derived column: Duration (Offset - Onset) ---------------------------\n",
    "casme_df[\"Duration\"] = casme_df[\"Offset\"] - casme_df[\"Onset\"]\n",
    "\n",
    "# --- Confirm changes ---------------------------------------------------------\n",
    "display(casme_df.head())\n",
    "display(casme_df.info())\n",
    "print(\"âœ… Cleaned Emotion label distribution:\")\n",
    "print(casme_df[\"Emotion\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.1.3 Save Cleaned CASME II Metadata (Safe Version)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Converts mixed-type columns to string so PyArrow can serialize them.\n",
    "# Replaces invalid numeric entries with NaN and stores as text-safe Parquet.\n",
    "# =============================================================================\n",
    "\n",
    "CASME_CLEANED_PATH = CHECKS_DIR / \"casme2_cleaned.parquet\"\n",
    "\n",
    "# --- Optional: Force all columns to string for safety ------------------------\n",
    "casme_df = casme_df.astype(str)\n",
    "\n",
    "# --- Save to Parquet ---------------------------------------------------------\n",
    "casme_df.to_parquet(CASME_CLEANED_PATH, index=False)\n",
    "print(f\"âœ… Saved CASME II cleaned metadata â†’ {CASME_CLEANED_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.1.4 ðŸ•·ï¸ Spider Check (Sanity check):\n",
    "# -----------------------------------------------------------------------------\n",
    "# # confirm file was saved and list folder contents\n",
    "# =============================================================================\n",
    "\n",
    "if CASME_CLEANED_PATH.exists():\n",
    "    print(f\"âœ… File exists at expected path: {CASME_CLEANED_PATH}\")\n",
    "    print(\"\\nðŸ“‚ Contents of checks folder:\")\n",
    "    for f in CHECKS_DIR.glob(\"*\"):\n",
    "        print(\" -\", f.name)\n",
    "else:\n",
    "    print(f\"âŒ File not found at: {CASME_CLEANED_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.2 | SMIC Cleaning & Structuring\n",
    "\n",
    "**Source:** `SMIC_VIS_E`, `SMIC_NIR_E`, and `SMIC_HS_E` Excel annotations  \n",
    "**Output:** `smic_cleaned.parquet`\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Load all three SMIC subsets (VIS, NIR, HS)  \n",
    "- Clean and unify structures  \n",
    "- Normalize emotion labels and create shared frame fields  \n",
    "- Save consolidated .parquet for fusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ðŸ—‚ï¸  File Discovery â€” Locate All .xlsx Files in RAW_DIR\n",
    "# -----------------------------------------------------------------------------\n",
    "# Goal:\n",
    "#   - Recursively search through all subdirectories in the raw data folder\n",
    "#   - Identify and print full paths of all Excel (.xlsx) files\n",
    "#   - Helps confirm visibility of annotation spreadsheets and debug path issues\n",
    "# =============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "for p in RAW_DIR.rglob(\"*.xlsx\"):\n",
    "    print(\"ðŸ“„ Found:\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.1  Load SMIC VIS-E Metadata\n",
    "# =============================================================================\n",
    "# Goal:\n",
    "#   - Read Excel spreadsheet containing visual modality emotion annotations\n",
    "#   - Tag rows with modality = \"VIS\" for fusion use later\n",
    "#   - Confirm successful load and inspect structure and class labels\n",
    "# =============================================================================\n",
    "\n",
    "# --- Define spreadsheet path for SMIC VIS-E modality -------------------------\n",
    "vis_path = RAW_DIR / \"SMIC\" / \"SMIC-E_raw image\" / \"VIS_long\" / \"SMIC_VIS_E_annotation.xlsx\"\n",
    "\n",
    "# --- Load the spreadsheet safely ---------------------------------------------\n",
    "try:\n",
    "    vis_df = pd.read_excel(vis_path)\n",
    "    vis_df['Modality'] = \"VIS\"  # Add modality tag\n",
    "    print(f\"âœ… Loaded VIS-E metadata: {vis_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ VIS-E metadata not found at: {vis_path}\")\n",
    "    vis_df = None\n",
    "\n",
    "# --- Preview structure if loaded correctly -----------------------------------\n",
    "if vis_df is not None:\n",
    "    # Show first few rows\n",
    "    display(vis_df.head())\n",
    "    \n",
    "    # Show column types and null counts\n",
    "    display(vis_df.info())\n",
    "\n",
    "    # View emotion label distribution\n",
    "    print(\"âœ… VIS-E label distribution:\")\n",
    "    print(vis_df['Emotion'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.2  Load SMIC NIR-E Metadata\n",
    "# =============================================================================\n",
    "# Goal:\n",
    "#   - Read Excel spreadsheet containing NIR modality annotations\n",
    "#   - Add modality tag for alignment in fusion step\n",
    "#   - Confirm successful load and inspect label structure\n",
    "# =============================================================================\n",
    "\n",
    "# --- Define spreadsheet path for SMIC NIR-E modality -------------------------\n",
    "nir_path = RAW_DIR / \"SMIC\" / \"SMIC-E_raw image\" / \"NIR_long\" / \"SMIC-NIR-E_annotation.xlsx\"\n",
    "\n",
    "# --- Load the spreadsheet safely ---------------------------------------------\n",
    "try:\n",
    "    nir_df = pd.read_excel(nir_path)\n",
    "    nir_df['Modality'] = \"NIR\"  # Add modality tag\n",
    "    print(f\"âœ… Loaded NIR-E metadata: {nir_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ NIR-E metadata not found at: {nir_path}\")\n",
    "    nir_df = None\n",
    "\n",
    "# --- Preview structure if loaded correctly -----------------------------------\n",
    "if nir_df is not None:\n",
    "    # Show first few rows\n",
    "    display(nir_df.head())\n",
    "    \n",
    "    # Show column types and null counts\n",
    "    display(nir_df.info())\n",
    "\n",
    "    # View emotion label distribution\n",
    "    print(\"âœ… NIR-E label distribution:\")\n",
    "    print(nir_df['Emotion'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.2  Load SMIC NIR-E Metadata\n",
    "# =============================================================================\n",
    "# Goal:\n",
    "#   - Read Excel spreadsheet containing NIR modality annotations\n",
    "#   - Add modality tag for alignment in fusion step\n",
    "#   - Confirm successful load and inspect label structure\n",
    "# =============================================================================\n",
    "\n",
    "# --- Define spreadsheet path for SMIC NIR-E modality -------------------------\n",
    "nir_path = RAW_DIR / \"SMIC\" / \"SMIC-E_raw image\" / \"NIR_long\" / \"SMIC-NIR-E_annotation.xlsx\"\n",
    "\n",
    "# --- Load the spreadsheet safely ---------------------------------------------\n",
    "try:\n",
    "    nir_df = pd.read_excel(nir_path)\n",
    "    nir_df['Modality'] = \"NIR\"  # Add modality tag\n",
    "    print(f\"âœ… Loaded NIR-E metadata: {nir_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ NIR-E metadata not found at: {nir_path}\")\n",
    "    nir_df = None\n",
    "\n",
    "# --- Preview structure if loaded correctly -----------------------------------\n",
    "if nir_df is not None:\n",
    "    # Show first few rows\n",
    "    display(nir_df.head())\n",
    "    \n",
    "    # Show column types and null counts\n",
    "    display(nir_df.info())\n",
    "\n",
    "    # View emotion label distribution\n",
    "    print(\"âœ… NIR-E label distribution:\")\n",
    "    print(nir_df['Emotion'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.3  Load SMIC HS-E Metadata\n",
    "# =============================================================================\n",
    "# Goal:\n",
    "#   - Load high-speed modality Excel file for SMIC\n",
    "#   - Add modality tag for downstream processing\n",
    "#   - Validate structure and review emotion label distribution\n",
    "# =============================================================================\n",
    "\n",
    "# --- Define spreadsheet path for SMIC HS-E modality --------------------------\n",
    "hs_path = RAW_DIR / \"SMIC\" / \"SMIC-E_raw image\" / \"HS_long\" / \"SMIC-HS-E_annotation_2019.xlsx\"\n",
    "\n",
    "# --- Load the spreadsheet safely ---------------------------------------------\n",
    "try:\n",
    "    hs_df = pd.read_excel(hs_path)\n",
    "    hs_df['Modality'] = \"HS\"  # Add modality tag\n",
    "    print(f\"âœ… Loaded HS-E metadata: {hs_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ HS-E metadata not found at: {hs_path}\")\n",
    "    hs_df = None\n",
    "\n",
    "# --- Preview structure if loaded correctly -----------------------------------\n",
    "if hs_df is not None:\n",
    "    # Show first few rows\n",
    "    display(hs_df.head())\n",
    "    \n",
    "    # Show column types and null counts\n",
    "    display(hs_df.info())\n",
    "\n",
    "    # View emotion label distribution\n",
    "    print(\"âœ… HS-E label distribution:\")\n",
    "    print(hs_df['Emotion'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.4 Clean & Concatenate SMIC Modalities\n",
    "# -----------------------------------------------------------------------------\n",
    "# Goal:\n",
    "#   - Standardize column structure across VIS, NIR, and HS SMIC subsets\n",
    "#   - Drop irrelevant or noisy columns (e.g., Unnamed, extra onset/offsets)\n",
    "#   - Normalize emotion labels and frame column names\n",
    "#   - Concatenate into one unified DataFrame: smic_df\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Define common columns to keep across all subsets ------------------------\n",
    "COMMON_COLS = [\"Subject\", \"Filename\", \"OnsetF\", \"OffsetF\", \"FirstF\", \"TotalVL\", \"Emotion\", \"Modality\"]\n",
    "\n",
    "# --- Select and copy only needed columns for each subset ---------------------\n",
    "vis_clean = vis_df[COMMON_COLS].copy()\n",
    "nir_clean = nir_df[COMMON_COLS].copy()\n",
    "hs_clean  = hs_df[COMMON_COLS].copy()\n",
    "\n",
    "# --- Rename columns to unified format ----------------------------------------\n",
    "rename_cols = {\n",
    "    \"OnsetF\": \"Onset\",\n",
    "    \"OffsetF\": \"Offset\",\n",
    "    \"FirstF\": \"First\",\n",
    "    \"TotalVL\": \"Duration\"\n",
    "}\n",
    "\n",
    "vis_clean.rename(columns=rename_cols, inplace=True)\n",
    "nir_clean.rename(columns=rename_cols, inplace=True)\n",
    "hs_clean.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# --- Normalize emotion labels ------------------------------------------------\n",
    "for df in [vis_clean, nir_clean, hs_clean]:\n",
    "    df[\"Emotion\"] = df[\"Emotion\"].str.strip().str.lower()\n",
    "\n",
    "# --- Add source tag for traceability -----------------------------------------\n",
    "for df in [vis_clean, nir_clean, hs_clean]:\n",
    "    df[\"SourceDataset\"] = \"SMIC\"\n",
    "\n",
    "# --- Concatenate all three subsets -------------------------------------------\n",
    "smic_df = pd.concat([vis_clean, nir_clean, hs_clean], ignore_index=True)\n",
    "print(f\"âœ… Unified SMIC dataset created: {smic_df.shape}\")\n",
    "\n",
    "# --- Final structure check ---------------------------------------------------\n",
    "display(smic_df.head(3))\n",
    "display(smic_df.info())\n",
    "print(\"âœ… Emotion label distribution:\")\n",
    "print(smic_df[\"Emotion\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.2.5 ðŸ’¾ Save Cleaned SMIC Metadata (Safe Version)\n",
    "# -----------------------------------------------------------------------------\n",
    "# - Converts all columns to string so PyArrow can serialize mixed types\n",
    "# - Stores result as a safe Parquet file for later fusion in Section 6.3\n",
    "# - Location: outputs/checks/smic_cleaned.parquet\n",
    "# =============================================================================\n",
    "\n",
    "SMIC_CLEANED_PATH = CHECKS_DIR / \"smic_cleaned.parquet\"\n",
    "\n",
    "# --- Optional: Force all columns to string (safe across inconsistent types) --\n",
    "smic_df = smic_df.astype(str)\n",
    "\n",
    "# --- Save to Parquet ---------------------------------------------------------\n",
    "smic_df.to_parquet(SMIC_CLEANED_PATH, index=False)\n",
    "print(f\"âœ… Saved SMIC cleaned metadata â†’ {SMIC_CLEANED_PATH}\")\n",
    "\n",
    "# --- ðŸ•·ï¸ Spider Check (Sanity check): confirm file was saved and list folder contents ----------\n",
    "if SMIC_CLEANED_PATH.exists():\n",
    "    print(f\"ðŸ“‚ Contents of checks folder:\")\n",
    "    for f in CHECKS_DIR.glob(\"*\"):\n",
    "        print(\" -\", f.name)\n",
    "else:\n",
    "    print(f\"âŒ File not found at: {SMIC_CLEANED_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.3 | Load Cleaned Metadata for Fusion\n",
    "\n",
    "Purpose:\n",
    " - Load the cleaned CASME II and SMIC metadata parquet files\n",
    " - Preview each dataset side by side before structural comparison\n",
    " - Ensure no data corruption and verify readiness for alignment\n",
    "\n",
    "\n",
    " **Input files**:\n",
    "\n",
    "| Dataset    | Path                                         | Shape     |\n",
    "|------------|----------------------------------------------|-----------|\n",
    "| CASME II   | `outputs/checks/casme2_cleaned.parquet`      | (255, 8)  |\n",
    "| SMIC       | `outputs/checks/smic_cleaned.parquet`        | (305, 9)  |\n",
    "\n",
    "\n",
    " **Note**: DAIC-WOZ is not used in this fusion. This is purely a facial microexpression metadata merge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.3.1 Load Cleaned Metadata for Fusion\n",
    "# =============================================================================\n",
    "# Purpose:\n",
    "#   - Load the cleaned CASME II and SMIC metadata parquet files\n",
    "#   - Preview each dataset side by side before structural comparison\n",
    "#   - Ensure no data corruption and verify readiness for alignment\n",
    "# =============================================================================\n",
    "\n",
    "# --- Load CASME II cleaned data ----------------------------------------------\n",
    "casme_path = CHECKS_DIR / \"casme2_cleaned.parquet\"\n",
    "casme_df   = pd.read_parquet(casme_path)\n",
    "print(f\"âœ… CASME II loaded: {casme_df.shape}\")\n",
    "\n",
    "# --- Load SMIC cleaned data --------------------------------------------------\n",
    "smic_path = CHECKS_DIR / \"smic_cleaned.parquet\"\n",
    "smic_df   = pd.read_parquet(smic_path)\n",
    "print(f\"âœ… SMIC loaded: {smic_df.shape}\")\n",
    "\n",
    "# --- Preview structure and content -------------------------------------------\n",
    "display(casme_df.head(3))\n",
    "display(smic_df.head(3))\n",
    "\n",
    "# --- Optional: Schema alignment diagnostic -----------------------------------\n",
    "print(\"ðŸ”· CASME II columns:\", casme_df.columns.tolist())\n",
    "print(\"ðŸ”· SMIC columns:    \", smic_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "---\n",
    "### 6.3.2 â€” Align CASME II and SMIC Metadata for Fusion\n",
    "\n",
    "This section ensures both datasets have identical schemas so we can concatenate them safely for multimodal emotion modeling.\n",
    "\n",
    "What will be done:\n",
    "- Rename SMICâ€™s Subject to match CASMEâ€™s SubjectID\n",
    "- Add missing columns to CASME II: Modality, SourceDataset\n",
    "- Fill missing Peak in SMIC with NaN\n",
    "- Reorder columns consistently across both datasets\n",
    "  >Final Schema (Target Order): \n",
    "      >[\"SubjectID\", \"Filename\", \"Onset\", \"Peak\", \"Offset\", \"ActionUnits\", \"Emotion\", \"Duration\", \"Modality\", \"SourceDataset\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.3.2 Align CASME II and SMIC Schemas for Fusion\n",
    "# -----------------------------------------------------------------------------\n",
    "# Ensures consistent column names, types, and order between datasets\n",
    "# to allow seamless concatenation and downstream modeling.\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# --- Rename SMIC's Subject â†’ SubjectID ---------------------------------------\n",
    "smic_df.rename(columns={\"Subject\": \"SubjectID\"}, inplace=True)\n",
    "\n",
    "# --- Add missing columns to CASME II -----------------------------------------\n",
    "casme_df[\"Modality\"] = \"CASME2\"\n",
    "casme_df[\"SourceDataset\"] = \"CASME2\"\n",
    "\n",
    "# --- Add missing column to SMIC ----------------------------------------------\n",
    "smic_df[\"Peak\"] = np.nan\n",
    "smic_df[\"ActionUnits\"] = np.nan  # If not already present â€” safe placeholder\n",
    "\n",
    "# --- Reorder columns to match target schema ----------------------------------\n",
    "COL_ORDER = [\"SubjectID\", \"Filename\", \"Onset\", \"Peak\", \"Offset\", \"ActionUnits\",\n",
    "             \"Emotion\", \"Duration\", \"Modality\", \"SourceDataset\"]\n",
    "\n",
    "casme_df = casme_df[COL_ORDER]\n",
    "smic_df = smic_df[COL_ORDER]\n",
    "\n",
    "# --- Concatenate both datasets -----------------------------------------------\n",
    "fusion_df = pd.concat([casme_df, smic_df], ignore_index=True)\n",
    "\n",
    "# --- Quick structure check ---------------------------------------------------\n",
    "print(f\"âœ… Fused dataset shape: {fusion_df.shape}\")\n",
    "display(fusion_df.head(3))\n",
    "display(fusion_df.info())\n",
    "print(\"âœ… Fused emotion distribution:\")\n",
    "print(fusion_df[\"Emotion\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 6.3.3 ðŸ’¾ Save Fused Microexpression Metadata (Safe Version)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Purpose:\n",
    "#   - Persist combined SMIC + CASME II metadata as .parquet\n",
    "#   - Ensures full reproducibility for Notebook 07 (Modeling & Analysis)\n",
    "#   - Converts columns to string (where needed) for Arrow safety\n",
    "# =============================================================================\n",
    "\n",
    "FUSED_META_PATH = CHECKS_DIR / \"fused_microexpression_metadata.parquet\"\n",
    "\n",
    "# --- Optional: force to string if you want absolute safety -------------------\n",
    "# fusion_df = fusion_df.astype(str)\n",
    "\n",
    "# --- Save to .parquet --------------------------------------------------------\n",
    "fusion_df.to_parquet(FUSED_META_PATH, index=False)\n",
    "print(f\"âœ… Saved fused metadata â†’ {FUSED_META_PATH}\")\n",
    "\n",
    "# --- ðŸ•·ï¸Spider Check: Confirm file exists -----------------------------------------------------\n",
    "if FUSED_META_PATH.exists():\n",
    "    print(\"ðŸ“‚ Contents of checks folder:\")\n",
    "    for f in CHECKS_DIR.glob(\"*\"):\n",
    "        print(\" -\", f.name)\n",
    "else:\n",
    "    print(\"âŒ Save failed â€” file not found at expected path.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "---\n",
    "#  Notebook 06 Complete: Microexpression Cleaning & Fusion Summary\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook performs structured loading, cleaning, and fusion of two multimodal microexpression datasets:\n",
    "\n",
    "- **CASME II**: Chinese Academy of Sciences Micro-Expression II\n",
    "- **SMIC**: Spontaneous Micro-Expression Corpus (VIS-E, NIR-E, HS-E modalities)\n",
    "\n",
    "These datasets are prepped for downstream emotion modeling, rule extraction, and semantic verification (Notebook 07+).\n",
    "\n",
    "---\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Cleaned and fused `.parquet` files saved to `outputs/checks/`:\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `casme2_cleaned.parquet` | Cleaned CASME II metadata |\n",
    "| `smic_cleaned.parquet` | Unified SMIC metadata across all 3 modalities |\n",
    "| `fused_microexpression_metadata.parquet` | Final aligned table (CASME II + SMIC) for modeling |\n",
    "\n",
    "---\n",
    "\n",
    "## Final Dataset Summary\n",
    "\n",
    "-  **Total Records**: 560  \n",
    "-  **Emotion Classes**: `['negative', 'positive', 'surprise', 'disgust', 'repression', 'happiness', 'sadness', 'fear', 'others']`  \n",
    "-  **Modality Tags**: VIS, NIR, HS, CASME II  \n",
    "-  **Schema Harmonized**: `['SubjectID', 'Filename', 'Onset', 'Peak', 'Offset', 'ActionUnits', 'Emotion', 'Duration', 'Modality', 'SourceDataset']`\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Proceed to **Notebook 07**:\n",
    "\n",
    ">  Frame-level expansion, feature extraction, and semantic affect labeling  \n",
    ">  Prepare fusion dataset for rule mining and multimodal emotion modeling\n",
    "\n",
    "---\n",
    "\n",
    "##  Acknowledgments\n",
    "\n",
    "This work reflects trauma-informed alignment goals. Each entry represents more than facial frames â€” itâ€™s a step toward systems that **see what others overlook.**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (trauma_ai)",
   "language": "python",
   "name": "trauma_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
