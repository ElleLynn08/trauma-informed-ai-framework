{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 01 - Import & Explore DAIC-WOZ Labels (then Clean)\n",
    "\n",
    "This notebook establishes the **labels foundation** for the trauma-informed AI pipeline. \n",
    "Before working with multimodal features (audio, video, text), we must import, validate, and lightly clean the ground-truth **PHQ-8 depression scores** from the AVEC 2017 challenge. \n",
    "\n",
    "## Objectives\n",
    "- **Load** the DAIC-WOZ / AVEC 2017 training labels (participant_id + PHQ-8 scores). \n",
    "- **Inspect** structure, missing values, duplicates, and valid ranges. \n",
    "- **Visualize** label distributions (continuous PHQ-8 and binary depressed vs. non-depressed). \n",
    "- **Clean minimally** (drop duplicates, enforce ranges, standardize IDs). \n",
    "- **Save outputs**: \n",
    " - A tiny shareable sample (for fast iteration). \n",
    " - A full cleaned artifact (for modeling, ignored by git). \n",
    "\n",
    "## Why This Matters\n",
    "Accurate labels are the backbone of supervised learning. By carefully auditing and documenting them first, we ensure that downstream feature engineering and modeling rest on a **clean, reproducible, and trustworthy foundation**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# --- bootstrap PYTHONPATH so repo utilities are importable ------------------------------\n",
    "# Why: Jupyter often runs from the `notebooks/` folder, so `utils/` (at repo root) isn't on sys.path.\n",
    "# This cell adds both ROOT and ROOT/utils to sys.path so `from utils.sanity ...` works reliably.\n",
    "import sys, pathlib\n",
    "CWD = pathlib.Path.cwd()\n",
    "ROOT = CWD if (CWD / \"utils\").exists() else CWD.parent # handles when notebook lives in notebooks/\n",
    "if str(ROOT) not in sys.path:\n",
    " sys.path.append(str(ROOT))\n",
    "if str(ROOT / \"utils\") not in sys.path:\n",
    " sys.path.append(str(ROOT / \"utils\"))\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"In sys.path:\", str(ROOT) in sys.path, str(ROOT/'utils') in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- environment sanity & project paths -------------------------------------------------\n",
    "# Why: print python path/versions and set up canonical DATA folders used throughout the project.\n",
    "from utils.sanity import sanity_env, setup_paths, set_seeds\n",
    "sanity_env(pkgs=(\"pandas\",\"numpy\",\"matplotlib\",\"seaborn\",\"sklearn\"))\n",
    "ROOT, DATA, RAW, CLEAN, OUT = setup_paths()\n",
    "set_seeds(42)\n",
    "ROOT, DATA, RAW, CLEAN, OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 1 - Discover raw files\n",
    "List data like files under `data/raw/` to confirm locations and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def list_files(base: Path, patterns=(\".csv\", \".tsv\", \".xlsx\", \".json\")):\n",
    " \"\"\"Return (relative_path, sizeMB) for readable data files, sorted by size desc.\"\"\"\n",
    " rows = []\n",
    " for p in base.rglob(\"*\"):\n",
    " if p.is_file() and p.suffix.lower() in patterns:\n",
    " rows.append((p.relative_to(base), round(p.stat().st_size/1_000_000, 2)))\n",
    " return sorted(rows, key=lambda x: (-x[1], str(x[0])))\n",
    "\n",
    "raw_list = list_files(RAW)\n",
    "print(f\"Found {len(raw_list)} candidate files under {RAW}\")\n",
    "for rel, mb in raw_list[:30]:\n",
    " print(f\"{str(rel):70s} {mb:6.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Step 2 - Load the Depression AVEC 2017 training labels\n",
    "We expect a file named like `train_split_Depression_AVEC2017.csv` containing **participant IDs**\n",
    "and **PHQ 8** totals. Adjust `labels_rel` below if your path differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Auto-find a likely labels file under RAW --------------------------------\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# reuse raw_list if it's already defined; otherwise rebuild it quickly\n",
    "try:\n",
    " raw_list\n",
    "except NameError:\n",
    " from pathlib import Path\n",
    " def list_files(base: Path, patterns=(\".csv\", \".tsv\", \".xlsx\", \".json\")):\n",
    " rows = []\n",
    " for p in base.rglob(\"*\"):\n",
    " if p.is_file() and p.suffix.lower() in patterns:\n",
    " rows.append((p.relative_to(base), round(p.stat().st_size/1_000_000, 2)))\n",
    " return sorted(rows, key=lambda x: (-x[1], str(x[0])))\n",
    " raw_list = list_files(RAW)\n",
    "\n",
    "def score_name(name: str) -> int:\n",
    " n = name.lower()\n",
    " score = 0\n",
    " # prioritize depression labels files\n",
    " if \"depression\" in n: score += 3\n",
    " if \"train_split\" in n or \"train\" in n: score += 2\n",
    " if \"avec2017\" in n or \"avec\" in n: score += 2\n",
    " if \"label\" in n or \"phq\" in n or \"phq8\" in n: score += 2\n",
    " if n.endswith(\".csv\"): score += 1\n",
    " return score\n",
    "\n",
    "candidates = sorted([(score_name(str(rel)), rel) for rel,_ in raw_list], reverse=True)\n",
    "top = [rel for sc, rel in candidates if sc > 0][:10]\n",
    "\n",
    "print(\"Top label-like candidates:\")\n",
    "for rel in top:\n",
    " print(\" \", rel)\n",
    "\n",
    "# pick the best guess\n",
    "labels_rel = top[0] if top else None\n",
    "labels_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- load the chosen labels file --------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "labels_path = RAW / \"train_split_Depression_AVEC2017.csv\" # use the top candidate\n",
    "assert labels_path.exists(), f\"Labels file not found: {labels_path}\"\n",
    "\n",
    "df = pd.read_csv(labels_path)\n",
    "\n",
    "print(\"Original columns:\", df.columns.tolist())\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Step 3 - Normalize column names; choose ID & label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize: strip, lowercase, spaces->underscores for consistent referencing\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "print(\"Normalized columns:\", df.columns.tolist())\n",
    "\n",
    "# For AVEC 2017 labels we expect these names; override if different:\n",
    "ID_COL = \"participant_id\"\n",
    "LABEL_COL = \"phq8_score\"\n",
    "\n",
    "assert ID_COL in df.columns, f\"{ID_COL} not in columns: {df.columns.tolist()}\"\n",
    "assert LABEL_COL in df.columns, f\"{LABEL_COL} not in columns: {df.columns.tolist()}\"\n",
    "\n",
    "# Standardize types: IDs as strings; coerce label to numeric\n",
    "df[ID_COL] = df[ID_COL].astype(str).str.strip()\n",
    "df[LABEL_COL] = pd.to_numeric(df[LABEL_COL], errors=\"coerce\")\n",
    "\n",
    "print(f\"Using ID_COL={ID_COL}, LABEL_COL={LABEL_COL}\")\n",
    "df[[ID_COL, LABEL_COL]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Step 4 - Overview & nulls audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick overview and null audit -------------------------------------------\n",
    "# Why: understand the shape of the dataset and check for missing values\n",
    "# across critical columns (IDs + PHQ8 scores).\n",
    "\n",
    "from utils.sanity import data_overview\n",
    "\n",
    "data_overview(df[[ID_COL, LABEL_COL]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Step 5 - Label distribution & integrity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Label distribution and integrity checks ---------------------------------\n",
    "# Why: \n",
    "# - visualize the PHQ8 score distribution (class imbalance, expected range 0-24)\n",
    "# - check for duplicate participant IDs\n",
    "# - confirm all scores fall in the valid range\n",
    "\n",
    "from utils.sanity import label_balance, check_integrity\n",
    "\n",
    "label_balance(df, label_col=LABEL_COL, binary_col=\"phq8_binary\")\n",
    "\n",
    "check_integrity(\n",
    " df,\n",
    " id_col=ID_COL,\n",
    " label_col=LABEL_COL,\n",
    " label_range=(0, 24) # valid PHQ8 score range\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Step 6 - Minimal cleaning (documented, reversible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Minimal cleaning --------------------------------------------------------\n",
    "# Why:\n",
    "# - Drop rows missing ID or PHQ8 score (can't be used downstream).\n",
    "# - Drop any duplicate IDs (should be 0, but defensive coding is good).\n",
    "# - Keep only scores in the valid PHQ8 range (0-24).\n",
    "\n",
    "clean = (\n",
    " df.dropna(subset=[ID_COL, LABEL_COL]) # drop rows with null ID or score\n",
    " .drop_duplicates(subset=[ID_COL]) # keep first occurrence per participant\n",
    " .query(f\"{LABEL_COL} >= 0 & {LABEL_COL} <= 24\") # enforce valid score range\n",
    " .copy()\n",
    ")\n",
    "\n",
    "# standardize ID again to string + strip whitespace\n",
    "clean[ID_COL] = clean[ID_COL].astype(str).str.strip()\n",
    "\n",
    "print(\"Before -> After:\", len(df), \"->\", len(clean))\n",
    "clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Step 7 - Save artifacts (tiny sample + full cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sanity import save_checkpoint\n",
    "\n",
    "# Tiny sample (<=200 rows) - safe to version if you want\n",
    "_ = save_checkpoint(clean, OUT / \"eda_sample.parquet\", n=min(200, len(clean)))\n",
    "\n",
    "# Full cleaned labels - ignored by git (lives in data/cleaned/)\n",
    "CLEAN.mkdir(parents=True, exist_ok=True)\n",
    "full_path = CLEAN / \"labels_clean.parquet\"\n",
    "clean.to_parquet(full_path, index=False)\n",
    "print(\"Saved:\", full_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7 - Save Artifacts (Tiny Sample + Full Cleaned)\n",
    "We checkpoint the cleaned dataset into two outputs:\n",
    "\n",
    "- **Tiny sample** (`eda_sample.parquet`) a lightweight 200-row slice for quick testing and sharing. \n",
    "- **Full cleaned labels** (`labels_clean.parquet`) the authoritative dataset, ignored by git to prevent large file commits. \n",
    "\n",
    "**Key Point:** Saving both a tiny and full version makes development easier (fast iterations) while preserving the complete, cleaned dataset for modeling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Appendix - Working Data Dictionary (Updated as I Go)\n",
    "\n",
    "- **participant_id** *(string)* - normalized unique subject identifier. \n",
    "- **phq8_score** *(int, 0-24)* - PHQ-8 depression severity total score. \n",
    "- **phq8_binary** *(int, 0-1)* - derived label (0 = non-depressed, 1 = depressed). \n",
    "- **gender** *(string)* - participant gender (encoding not yet confirmed). \n",
    "- **phq8_nointerest** *(int, 0-3)* - item 1 (loss of interest/pleasure). \n",
    "- **phq8_depressed** *(int, 0-3)* - item 2 (feeling down/depressed). \n",
    "- **phq8_sleep** *(int, 0-3)* - item 3 (sleep disturbance). \n",
    "- **phq8_tired** *(int, 0-3)* - item 4 (fatigue/low energy). \n",
    "- **phq8_appetite** *(int, 0-3)* - item 5 (appetite changes). \n",
    "- **phq8_failure** *(int, 0-3)* - item 6 (feelings of failure/self-worth). \n",
    "- **phq8_concentrating** *(int, 0-3)* - item 7 (trouble concentrating). \n",
    "- **phq8_moving** *(int, 0-3)* - item 8 (psychomotor agitation/retardation). \n",
    "\n",
    "**Provenance:** Source file = `train_split_Depression_AVEC2017.csv` (DAIC-WOZ / AVEC 2017 depression dataset). \n",
    "\n",
    "**Assumptions:** \n",
    "- Valid PHQ-8 score range is 0-24. \n",
    "- No duplicate participant IDs. \n",
    "- `phq8_binary` derived using clinical cutoff (e.g., 10). \n",
    "\n",
    "**Artifacts generated:** \n",
    "- `outputs/eda_sample.parquet` shareable sample \n",
    "- `data/cleaned/labels_clean.parquet` full cleaned labels table \n",
    "\n",
    "**Next:** \n",
    "- Confirm gender encoding. \n",
    "- Optionally join with demographics/transcripts on `participant_id`. \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Closing Summary\n",
    "In this notebook we successfully:\n",
    "\n",
    "1. Imported and verified raw DAIC-WOZ depression label files. \n",
    "2. Normalized column names, standardized IDs, and enforced valid ranges. \n",
    "3. Audited dataset completeness and confirmed no missing values in critical fields. \n",
    "4. Visualized PHQ-8 distributions, noting a class imbalance (~72% vs. ~28%). \n",
    "5. Performed minimal but effective cleaning to remove duplicates and invalid rows. \n",
    "6. Saved both lightweight and full cleaned artifacts for downstream use. \n",
    "\n",
    "This establishes a **clean, reproducible foundation** for modeling. The outputs from this notebook will directly feed into feature engineering, baseline models, and future multimodal fusion experiments.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "**Next Steps ** Proceed to [02_model_baselines.ipynb](./02_model_baselines.ipynb), \n",
    "where we establish baseline classifiers (Dummy vs. Logistic) and address the class imbalance identified here.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
