{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 01 - Import & Explore DAIC WOZ Labels (then Clean)\n",
    "\n",
    "This notebook focuses on **importing** and **exploring** the DAIC WOZ labels first; a small,\n",
    "clearly documented **cleaning step** comes *after* we understand the data (drop NAs/dupes,\n",
    "keep valid PHQ 8 range). Comments walk you through the *why* behind each step.\n",
    "\n",
    "**Goals**\n",
    "- Load the Depression AVEC 2017 training labels (participant_id + PHQ 8).\n",
    "- Inspect structure, missing values, and value ranges.\n",
    "- Visualize the label distribution.\n",
    "- Do a minimal, safe cleaning pass (documented).\n",
    "- Save a tiny checkpoint sample (shareable) and a full cleaned artifact (local, ignored by git).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# --- bootstrap PYTHONPATH so repo utilities are importable ------------------------------\n",
    "# Why: Jupyter often runs from the `notebooks/` folder, so `utils/` (at repo root) isn't on sys.path.\n",
    "# This cell adds both ROOT and ROOT/utils to sys.path so `from utils.sanity ...` works reliably.\n",
    "import sys, pathlib\n",
    "CWD = pathlib.Path.cwd()\n",
    "ROOT = CWD if (CWD / \"utils\").exists() else CWD.parent # handles when notebook lives in notebooks/\n",
    "if str(ROOT) not in sys.path:\n",
    " sys.path.append(str(ROOT))\n",
    "if str(ROOT / \"utils\") not in sys.path:\n",
    " sys.path.append(str(ROOT / \"utils\"))\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"In sys.path:\", str(ROOT) in sys.path, str(ROOT/'utils') in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- environment sanity & project paths -------------------------------------------------\n",
    "# Why: print python path/versions and set up canonical DATA folders used throughout the project.\n",
    "from utils.sanity import sanity_env, setup_paths, set_seeds\n",
    "sanity_env(pkgs=(\"pandas\",\"numpy\",\"matplotlib\",\"seaborn\",\"sklearn\"))\n",
    "ROOT, DATA, RAW, CLEAN, OUT = setup_paths()\n",
    "set_seeds(42)\n",
    "ROOT, DATA, RAW, CLEAN, OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 1 - Discover raw files\n",
    "List data like files under `data/raw/` to confirm locations and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def list_files(base: Path, patterns=(\".csv\", \".tsv\", \".xlsx\", \".json\")):\n",
    " \"\"\"Return (relative_path, sizeMB) for readable data files, sorted by size desc.\"\"\"\n",
    " rows = []\n",
    " for p in base.rglob(\"*\"):\n",
    " if p.is_file() and p.suffix.lower() in patterns:\n",
    " rows.append((p.relative_to(base), round(p.stat().st_size/1_000_000, 2)))\n",
    " return sorted(rows, key=lambda x: (-x[1], str(x[0])))\n",
    "\n",
    "raw_list = list_files(RAW)\n",
    "print(f\"Found {len(raw_list)} candidate files under {RAW}\")\n",
    "for rel, mb in raw_list[:30]:\n",
    " print(f\"{str(rel):70s} {mb:6.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Step 2 - Load the Depression AVEC 2017 training labels\n",
    "We expect a file named like `train_split_Depression_AVEC2017.csv` containing **participant IDs**\n",
    "and **PHQ 8** totals. Adjust `labels_rel` below if your path differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Auto-find a likely labels file under RAW --------------------------------\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# reuse raw_list if it's already defined; otherwise rebuild it quickly\n",
    "try:\n",
    " raw_list\n",
    "except NameError:\n",
    " from pathlib import Path\n",
    " def list_files(base: Path, patterns=(\".csv\", \".tsv\", \".xlsx\", \".json\")):\n",
    " rows = []\n",
    " for p in base.rglob(\"*\"):\n",
    " if p.is_file() and p.suffix.lower() in patterns:\n",
    " rows.append((p.relative_to(base), round(p.stat().st_size/1_000_000, 2)))\n",
    " return sorted(rows, key=lambda x: (-x[1], str(x[0])))\n",
    " raw_list = list_files(RAW)\n",
    "\n",
    "def score_name(name: str) -> int:\n",
    " n = name.lower()\n",
    " score = 0\n",
    " # prioritize depression labels files\n",
    " if \"depression\" in n: score += 3\n",
    " if \"train_split\" in n or \"train\" in n: score += 2\n",
    " if \"avec2017\" in n or \"avec\" in n: score += 2\n",
    " if \"label\" in n or \"phq\" in n or \"phq8\" in n: score += 2\n",
    " if n.endswith(\".csv\"): score += 1\n",
    " return score\n",
    "\n",
    "candidates = sorted([(score_name(str(rel)), rel) for rel,_ in raw_list], reverse=True)\n",
    "top = [rel for sc, rel in candidates if sc > 0][:10]\n",
    "\n",
    "print(\"Top label-like candidates:\")\n",
    "for rel in top:\n",
    " print(\" \", rel)\n",
    "\n",
    "# pick the best guess\n",
    "labels_rel = top[0] if top else None\n",
    "labels_rel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- load the chosen labels file --------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "labels_path = RAW / \"train_split_Depression_AVEC2017.csv\" # use the top candidate\n",
    "assert labels_path.exists(), f\"Labels file not found: {labels_path}\"\n",
    "\n",
    "df = pd.read_csv(labels_path)\n",
    "\n",
    "print(\"Original columns:\", df.columns.tolist())\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Step 3 - Normalize column names; choose ID & label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize: strip, lowercase, spaces->underscores for consistent referencing\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "print(\"Normalized columns:\", df.columns.tolist())\n",
    "\n",
    "# For AVEC 2017 labels we expect these names; override if different:\n",
    "ID_COL = \"participant_id\"\n",
    "LABEL_COL = \"phq8_score\"\n",
    "\n",
    "assert ID_COL in df.columns, f\"{ID_COL} not in columns: {df.columns.tolist()}\"\n",
    "assert LABEL_COL in df.columns, f\"{LABEL_COL} not in columns: {df.columns.tolist()}\"\n",
    "\n",
    "# Standardize types: IDs as strings; coerce label to numeric\n",
    "df[ID_COL] = df[ID_COL].astype(str).str.strip()\n",
    "df[LABEL_COL] = pd.to_numeric(df[LABEL_COL], errors=\"coerce\")\n",
    "\n",
    "print(f\"Using ID_COL={ID_COL}, LABEL_COL={LABEL_COL}\")\n",
    "df[[ID_COL, LABEL_COL]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Step 4 - Overview & nulls audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick overview and null audit -------------------------------------------\n",
    "# Why: understand the shape of the dataset and check for missing values\n",
    "# across critical columns (IDs + PHQ8 scores).\n",
    "\n",
    "from utils.sanity import data_overview\n",
    "\n",
    "data_overview(df[[ID_COL, LABEL_COL]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Step 5 - Label distribution & integrity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Label distribution and integrity checks ---------------------------------\n",
    "# Why: \n",
    "# - visualize the PHQ8 score distribution (class imbalance, expected range 0-24)\n",
    "# - check for duplicate participant IDs\n",
    "# - confirm all scores fall in the valid range\n",
    "\n",
    "from utils.sanity import label_balance, check_integrity\n",
    "\n",
    "label_balance(df, label_col=LABEL_COL, binary_col=\"phq8_binary\")\n",
    "\n",
    "check_integrity(\n",
    " df,\n",
    " id_col=ID_COL,\n",
    " label_col=LABEL_COL,\n",
    " label_range=(0, 24) # valid PHQ8 score range\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Step 6 - Minimal cleaning (documented, reversible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Minimal cleaning --------------------------------------------------------\n",
    "# Why:\n",
    "# - Drop rows missing ID or PHQ8 score (can't be used downstream).\n",
    "# - Drop any duplicate IDs (should be 0, but defensive coding is good).\n",
    "# - Keep only scores in the valid PHQ8 range (0-24).\n",
    "\n",
    "clean = (\n",
    " df.dropna(subset=[ID_COL, LABEL_COL]) # drop rows with null ID or score\n",
    " .drop_duplicates(subset=[ID_COL]) # keep first occurrence per participant\n",
    " .query(f\"{LABEL_COL} >= 0 & {LABEL_COL} <= 24\") # enforce valid score range\n",
    " .copy()\n",
    ")\n",
    "\n",
    "# standardize ID again to string + strip whitespace\n",
    "clean[ID_COL] = clean[ID_COL].astype(str).str.strip()\n",
    "\n",
    "print(\"Before -> After:\", len(df), \"->\", len(clean))\n",
    "clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Step 7 - Save artifacts (tiny sample + full cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.sanity import save_checkpoint\n",
    "\n",
    "# Tiny sample (<=200 rows) -> safe for versioning if you want\n",
    "_ = save_checkpoint(clean, OUT / \"eda_sample.parquet\", n=min(200, len(clean)))\n",
    "\n",
    "# Full cleaned labels -> goes to data/cleaned (ignored by git via .gitignore)\n",
    "CLEAN.mkdir(parents=True, exist_ok=True)\n",
    "full_path = CLEAN / \"labels_clean.parquet\"\n",
    "clean.to_parquet(full_path, index=False)\n",
    "print(\"Saved:\", full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Appendix - Working data dictionary (update as you go)\n",
    "- `participant_id` *(string)* - normalized unique subject identifier.\n",
    "- `phq8_score` *(int 0..24)* - PHQ 8 depression severity total.\n",
    "\n",
    "**Notes:** Add any additional columns you plan to join later (e.g., demographics, transcripts).\n",
    "Document units and valid ranges here as they become relevant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "---\n",
    "### ✅ Commit suggestions (use from terminal)\n",
    "- `EDA: env sanity + paths; discovered raw files`\n",
    "- `EDA: loaded AVEC 2017 labels; normalized columns; set ID+label`\n",
    "- `EDA: overview/nulls, distribution, integrity checks`\n",
    "- `EDA: minimal cleaning; saved sample + full cleaned parquet`\n",
    "\n",
    "### ️ Next\n",
    "- Join with other tables (e.g., demographics) using `participant_id`.\n",
    "- Begin `feature/model-baselines` branch: train/test split + baseline classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
